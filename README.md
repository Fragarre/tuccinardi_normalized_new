Stylometric Analysis with Normalized SPI (Tuccinardi Method)
Overview

This project implements a stylometric analysis workflow based on character n-grams and the Tuccinardi SPI (Stylistic Profile Index) similarity measure.

The program is designed to evaluate whether a doubtful text stylistically aligns with a corpus of certain texts attributed to a given author.

The methodology combines:

Character n-gram extraction

L1 normalization

Similarity computation (SPI)

Z-score standardization

Statistical evaluation using either:

Studentâ€™s t distribution (small sample size)

Normal distribution (larger sample size)

The output includes numerical results and graphical visualizations to assist interpretation.

Methodological Foundations
1. Character n-grams

The program extracts character n-grams (typically 3-grams or 4-grams) from each text fragment.

3-grams capture general linguistic habits (morphological patterns, orthographic tendencies).

4-grams capture more specific stylistic sequences (recurrent formulae, syntactic patterns).

The choice of n affects sensitivity and variance in the results.

2. L1 Normalization

Each text is represented as a frequency vector of n-grams.

L1 normalization transforms raw counts into proportions:

ğ‘£
ğ‘–
â€²
=
ğ‘£
ğ‘–
âˆ‘
ğ‘£
ğ‘–
v
i
â€²
	â€‹

=
âˆ‘v
i
	â€‹

v
i
	â€‹

	â€‹


This ensures:

Each text is treated as a distribution of stylistic habits.

Text length does not distort similarity.

Comparisons are based on stylistic profile rather than volume.

3. SPI Similarity (Tuccinardi)

The SPI index measures similarity between normalized frequency vectors.

The result is a similarity score for:

Each certain text vs. the rest of the certain corpus

The doubtful text vs. the certain corpus

This produces a distribution of similarity values representing the authorâ€™s stylistic baseline.

Statistical Evaluation
1. Z-score Standardization

The similarity of the doubtful text is evaluated relative to the distribution of similarities among the certain texts:

ğ‘§
=
ğ‘¥
âˆ’
ğœ‡
ğœ
z=
Ïƒ
xâˆ’Î¼
	â€‹


Where:

ğ‘¥
x = similarity of doubtful text

ğœ‡
Î¼ = mean similarity among certain texts

ğœ
Ïƒ = standard deviation

The z-score indicates how many standard deviations the doubtful text lies from the authorial norm.

2. Choice of Statistical Distribution

Depending on the number of fragments (n):

Small sample (typically n â‰¤ 30) â†’ Studentâ€™s t distribution

Larger sample â†’ Normal distribution

This adjustment allows proper estimation of statistical significance.

Graphical Output

The program generates visualizations such as:

Distribution plots (histogram + density curve)

Boxplots of similarity values

Z-score distribution plot

These graphs allow visual inspection of:

Central tendency

Dispersion

Outlier position of the doubtful text

Interpretation of Results
Step 1: Evaluate Central Tendency

Examine the mean similarity among certain texts.

A high and compact mean suggests a consistent stylistic profile.

Step 2: Examine Dispersion

The standard deviation reflects stylistic variability within the authorâ€™s corpus.

Low dispersion â†’ strong stylistic cohesion

High dispersion â†’ internal stylistic heterogeneity

This directly affects the reliability of classification.

Step 3: Locate the Doubtful Text

Interpret the z-score:

Z-score range	Interpretation
|z| < 1	Fully compatible with authorial norm
1 â‰¤ |z| < 2	Slight deviation, stylistically plausible
2 â‰¤ |z| < 3	Significant deviation
|z| â‰¥ 3	Strong stylistic divergence
Step 4: Consider Genre and Register

A deviation does not automatically imply different authorship.

Differences may reflect:

Genre shift (didactic vs. rhetorical)

Chronological development

Intended audience

Transmission history

Interpretation must therefore combine statistical evidence with philological judgment.

Comparative Use of Different n-grams

Running the analysis with multiple n-gram sizes (e.g., 3 and 4) increases robustness.

If both analyses converge â†’ strong evidence.

If results diverge â†’ possible genre or register variation.

If deviation appears only with larger n-grams â†’ surface stylistic variation rather than deep linguistic divergence.

Intended Use

This tool is designed for:

Authorship attribution studies

Internal consistency analysis within a corpus

Evaluation of doubtful works

Quantitative support for philological hypotheses

It does not replace traditional philological analysis, but provides statistically grounded stylistic evidence to inform it.

Conceptual Summary

The program models each text as a probabilistic distribution of micro-stylistic features.

Authorship compatibility is assessed by measuring whether the doubtful text behaves statistically like the known works of the author.

The central interpretive question is not:

â€œIs the similarity high?â€

but rather:

â€œIs the doubtful text statistically indistinguishable from the authorial distribution?â€